\PassOptionsToClass{}{beamer}
\documentclass[serif,aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{ragged2e}
\usepackage{colortbl}

%\StartShownPreambleCommands
\usepackage{amsmath,esint}
\usepackage[british]{babel}
\usetheme{Warsaw}
\usecolortheme{rose}
\usepackage{amsfonts,amssymb}
\usepackage{pgfplots}
\usepackage{ mathrsfs }
\usepackage{caption}

\usepackage{gensymb}
\usepackage{color}
\usepackage{url}
\usetikzlibrary{shapes,backgrounds,calc, positioning}

\usepackage{tkz-euclide}
\usetkzobj{all}
\usepackage{tkz-fct}  
\usetikzlibrary{calc}
\usepackage{tikz,calc}

\usepackage[ruled]{algorithm2e}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\usepackage{animate} 
\usepackage{ragged2e}
\usepackage{bbm}
\usepackage{soul,color}

\newcommand{\highlight}[1]{%
  \colorbox{red!50}{$\displaystyle#1$}}

\DeclareMathOperator*{\minimize}{minimize}

\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}

\renewcommand{\thealgocf}{}

\newcommand\myheading[1]{%
  \par\bigskip
  {\Large\bfseries#1}\par\smallskip}


\makeatletter
\newcommand\titlegraphicii[1]{\def\inserttitlegraphicii{#1}}
\titlegraphicii{}
\setbeamertemplate{title page}
{
  \vspace{0.3in}
  \vbox{}
  \begin{centering}
    \begin{beamercolorbox}[sep=8pt,center]{title}
      \usebeamerfont{title}\inserttitle\par%
      \ifx\insertsubtitle\@empty%
      \else%
        \vskip0.25em%
        {\usebeamerfont{subtitle}\usebeamercolor[fg]{subtitle}\insertsubtitle\par}%
      \fi%     
    \end{beamercolorbox}%
    \vskip1em\par
    \begin{beamercolorbox}[sep=8pt,center]{date}
      \usebeamerfont{date}\insertdate
    \end{beamercolorbox}%\vskip0.5em
    \begin{beamercolorbox}[sep=8pt,center]{author}
      \usebeamerfont{author}\insertauthor
    \end{beamercolorbox}
    \begin{beamercolorbox}[sep=8pt,center]{institute}
      \usebeamerfont{institute}\insertinstitute
    \end{beamercolorbox}
  \end{centering}
  %\vfill
}
\makeatother
\author{Mitesh M. Khapra}
\author{Mitesh M. Khapra}
\title{CS7015 (Deep Learning) : Lecture 10}
\subtitle{Learning Vectorial Representations Of Words}
\institute{Department of Computer Science and Engineering\\ Indian Institute of Technology Madras}
\date{}
\titlegraphic{\includegraphics[height=1cm,width=2cm]{images/iitm_logo.png}}


\begin{document}

%\def\alpha{3} 

\newcommand\derivative[5]{%
	\tkzDefPointByFct[draw](#1) \tkzGetPoint{start}
	\tkzDefPointByFct[draw](#2) \tkzGetPoint{end}
	\draw[thin,|-|,yshift=-3pt] (start) -- node[black,fill=white,#5] {#3}(start-|end);
	\draw[thin,|-|,xshift=3pt] (start-|end) -- node[black,fill=white,right] {#4}(end);
	%\draw[thin] (start) --(end); 
}
\begin{frame}
	\myheading{Module 10.10: Relation between SVD \& word2Vec}
\end{frame}

\begin{frame}
	\begin{block}{The story ahead ...}
		\onslide<1->{
			\begin{itemize}\justifying
				\item Continuous bag of words model
				\item Skip gram model with negative sampling (the famous word2vec)
				\item GloVe word embeddings
				\item Evaluating word embeddings
				\item \textcolor<1->{red}{Good old SVD does just fine!!}
			\end{itemize}}
	\end{block}
\end{frame}


\begin{frame}
	\begin{columns}
		\column{0.5\textwidth}
		\begin{overlayarea}{\textwidth}{\textheight}
			\include{modules/Module10/tikz_images/sg_1}
		\end{overlayarea}
		\column{0.5\textwidth}
		\begin{overlayarea}{\textwidth}{\textheight}
			\footnotesize{\begin{itemize} \justifying
					\onslide<1->{\item Recall that SVD does a matrix factorization of the co-occurrence matrix}
					      \onslide<2->{\item Levy et.al [2015] show that word2vec also implicitly does a matrix factorization}
					      \onslide<3->{\item What does this mean ?}
					      \onslide<4->{\item Recall that word2vec gives us $W_{context}$  $\&$  $W_{word}$ }.
					      \onslide<5->{\item Turns out that we can also show that
					      \vspace{-0.1in}
					      \begin{align*}
						      M = W_{context}*W_{word}
					      \end{align*}
					      where
					      \begin{align*}
						      M_{ij} & = PMI(w_i,c_i)-log(k)               \\
						      k      & = \text{number of negative samples}
					      \end{align*}
					      }
					      \vspace{-0.1in}
					      \onslide<6->{\item So essentially, word2vec factorizes a matrix M which is related to the PMI based co-occurrence matrix (very similar to what SVD does)}

				\end{itemize}}
		\end{overlayarea}
	\end{columns}
\end{frame}
\end{document}
