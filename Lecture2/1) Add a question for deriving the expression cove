1) Add a question for deriving the expression covered in lecture 1 
2) For question 2, define f as tanh
3) For question 3d ask "Can you think of a way of improving this estimation"
4) Improve 1.3 on deriatives involving matrix and vector operations
5) Keep question 1 given by Dilip
6) Revisit Question 1 and Question2 created by Ayesha and convert them into something which requires them to answer why the minima is obtained at a point where derivative is 0
7) Modify questions 7 and 8 created by Ashish Mishra 
8) KL divergence and loglikelihood are the same, a question on calculating cross entropy
9) softmax and normalization

++++++++++++++
Course timings
Assignments
	- substitute by Research Project
	- 7-8 assignments
	- talk about study assignments
	_ no extensions on any deadlines 
	- policy about mobile phones
Penalty for Copying ?
Attendance
	- checksum